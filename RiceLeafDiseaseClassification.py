# -*- coding: utf-8 -*-
"""demo

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17KzKGAIO5HcR_gzfAH5fC6YqRorJdAGz

import pakages
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import os
from tensorflow import keras
from keras import Sequential
from keras.preprocessing.image import ImageDataGenerator, load_img
from keras.layers import Conv2D,Flatten,Dense,Dropout,BatchNormalization,MaxPool2D
from keras.callbacks import EarlyStopping,ReduceLROnPlateau
import matplotlib.pyplot as plt
import cv2
import numpy as np
import tensorflow
import random
from google.colab.patches import cv2_imshow
# %matplotlib inline

"""Mounting Drive and Path setting"""

from google.colab import drive
drive.mount('/content/drive')

path  = '/content/drive/My Drive/leaf_disease/BrownSpot'
path1 = '/content/drive/My Drive/leaf_disease/Healthy'

l = os.listdir(path)
l1 = os.listdir(path1)

bs = []
for i in range(150):
    img_arr = cv2.imread((os.path.join(path,l[i])),-1)
    new_arr = cv2.resize(img_arr,(512,512))
    bs.append([new_arr,0])
len(bs)

h = []
for i in range(150):
    img_arr = cv2.imread((os.path.join(path1,l1[i])),-1)
    new_arr = cv2.resize(img_arr,(512,512))
    h.append([new_arr,1])
len(h)

l = bs + h
random.shuffle(l)
len(l)

x = []
y = []
for img,label in l:
    x.append(img)
    y.append(label)

x = np.array(x)
x.shape

cv2_imshow(x[0])

print(y[0])
#0 --> BrownSpot
#1 --> Healthy

print(y)

import tensorflow
y = tensorflow.keras.utils.to_categorical(y,num_classes=2)

y[:5]

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.33,random_state = 1)

len(x_train)

y_train = np.array(y_train)
y_test = np.array(y_test)

x_train.shape

y_train.shape

"""Classification model"""

import tensorflow as tf
import os
from tensorflow import keras
from keras import Sequential
from keras.layers import (Conv2D,Flatten,Dense,Dropout,
BatchNormalization,ZeroPadding2D,MaxPooling2D,GlobalAveragePooling2D,Activation,LeakyReLU)
from keras.optimizers import RMSprop, SGD
from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint

class myCallBacks(tf.keras.callbacks.Callback):
    def end_of_epoch(self,epoch,logs = {}):
        if(logs.get('accuracy') >= 0.97):
            print('\n accuracy achived above 95% \n')
            self.model.stop_training = True

model = Sequential()  
model.add(Conv2D(96, (11, 11), input_shape = (512,512,3), padding='same')) 
model.add(Activation('relu')) 
model.add(MaxPooling2D(pool_size=(2, 2))) 
 
model.add(Conv2D(128, (5, 5), padding='same')) 
model.add(Activation('relu')) 
model.add(MaxPooling2D(pool_size=(2, 2),strides=2)) 
model.add(ZeroPadding2D((1,1))) 

model.add(Conv2D(384, (3, 3), padding='same')) 
model.add(Activation('relu')) 
model.add(ZeroPadding2D((1,1))) 
  
model.add(Conv2D(192, (3, 3), padding='same')) 
model.add(Activation('relu')) 
model.add(ZeroPadding2D((1,1))) 
  
model.add(Conv2D(128, (3, 3), padding='same')) 
model.add(Activation('relu')) 
model.add(MaxPooling2D(pool_size=(2, 2))) 
model.add(GlobalAveragePooling2D()) 
#---------------ANN----------------------------------  
model.add(Dense(4096, kernel_initializer='glorot_normal')) 
model.add(Activation('relu')) 
model.add(Dropout(0.5)) 
 
model.add(Dense(4096, kernel_initializer='glorot_normal')) 
model.add(Activation('relu')) 
model.add(Dropout(0.5)) 
 
model.add(Dense(2, kernel_initializer='glorot_normal')) 
model.add(Activation('softmax')) 


reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',
                              patience=3,
                              factor = 0.3,
                             min_lr=0.0001)

model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])
print(model.summary())

intermediate_layer_model = keras.Model(inputs=model.input,
                                 outputs=model.get_layer('dense_2').output)

cnn_x_train = intermediate_layer_model.predict(x_train)
cnn_x_test = intermediate_layer_model.predict(x_test)

n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)
min_samples_split = [2, 5, 10]
min_samples_leaf = [1, 2, 4]
bootstrap = [True, False]
random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV,RandomizedSearchCV
rf = RandomForestClassifier()
rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, 
                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)
rf_random.fit(cnn_x_train, y_train)

from sklearn.metrics import accuracy_score
rf = rf_random.best_estimator_
predictions = rf.predict(cnn_x_test)
accuracy_score(predictions , y_test)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

